{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17f8a3-f983-4dde-ba5a-b22ee93aaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scienceplots\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import pprint\n",
    "from shapely.geometry import Polygon\n",
    "plt.style.use(['science', 'grid', 'ieee'])\n",
    "\n",
    "from utils import (\n",
    "    load_dataset,\n",
    "    get_images,\n",
    "    transform_points,\n",
    "    get_densities,\n",
    "    predict,\n",
    "    calculate_errors,\n",
    "    get_result_dict,\n",
    "    SCALING_FACTOR,\n",
    "    plot_setup, \n",
    "    plot_setup_noised,\n",
    "    plot_predictions,\n",
    "    add_outlier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41de1e-f49c-4ee1-91b6-fc2205ea2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(points, keys):\n",
    "    filtered = {key: points[key] for key in keys}\n",
    "    return filtered\n",
    "\n",
    "def conduct_experiment(pv_img, tv_img, plot=True, print_errors=True, used_ref_points=None, return_homography=False):\n",
    "    # Load Data\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "    \n",
    "    if used_ref_points:\n",
    "        reference_pts_pv = filter_points(reference_pts_pv, used_ref_points)\n",
    "        reference_pts_tv = filter_points(reference_pts_tv, used_ref_points)\n",
    "        \n",
    "    # Transform Points to Homogeneous Numpy arrays\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    # Calculate Homography\n",
    "    h, _ = cv2.findHomography(\n",
    "        reference_pts_pv_arr,\n",
    "        reference_pts_tv_arr,\n",
    "        # method = cv2.RANSAC,\n",
    "        method = 0,\n",
    "    )\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    # Get Pixel Densities\n",
    "    reference_densities = get_densities(reference_pts_tv_arr, h_inv)\n",
    "    validation_densities = get_densities(validation_pts_tv_arr, h_inv)\n",
    "    \n",
    "    # Predict Points\n",
    "    predicted_reference_pts_tv = predict(reference_pts_pv_arr, h)\n",
    "    predicted_validation_pts_tv = predict(validation_pts_pv_arr, h)\n",
    "    \n",
    "    # Errors\n",
    "    reference_errors = calculate_errors(predicted_reference_pts_tv, reference_pts_tv_arr)\n",
    "    validation_errors = calculate_errors(predicted_validation_pts_tv, validation_pts_tv_arr)\n",
    "\n",
    "    # Combine Results in Dictionary\n",
    "    reference_result_dict = get_result_dict(reference_pts_pv, reference_pts_tv_arr, predicted_reference_pts_tv, reference_errors, reference_densities, reference_pts_pv_arr)\n",
    "    validation_result_dict = get_result_dict(validation_pts_pv, validation_pts_tv_arr, predicted_validation_pts_tv, validation_errors, validation_densities, reference_pts_pv_arr)\n",
    "    \n",
    "    # Print Errors\n",
    "    if print_errors:\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) :.2f} PX!')\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "        print('---')\n",
    "        print(f'Validation Error: {np.mean(validation_errors):.2f} PX!')\n",
    "        print(f'Validation Error: {np.mean(validation_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "    \n",
    "    # Plots\n",
    "    if plot:\n",
    "        plot_setup(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "        plot_predictions(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "    if return_homography:\n",
    "        return reference_result_dict, validation_result_dict, h\n",
    "    return reference_result_dict, validation_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce70518-06aa-4daa-8de5-64f466c89486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(pv_imgs, tv_img):\n",
    "    dataframe = pd.DataFrame()\n",
    "    rows = []\n",
    "    for pv_img in pv_imgs:\n",
    "        print(pv_img)\n",
    "        reference_result_dict, validation_result_dict = conduct_experiment(pv_img, tv_img, plot=False, print_errors=True)\n",
    "        for pt, pt_dict in reference_result_dict.items():\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['img'] = pv_img\n",
    "            pt_dict['point_type'] = 'reference'\n",
    "            rows.append(pt_dict) \n",
    "        for pt, pt_dict in validation_result_dict.items():\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['img'] = pv_img\n",
    "            pt_dict['point_type'] = 'validation' \n",
    "            rows.append(pt_dict) \n",
    "    dataframe = pd.DataFrame(rows)  \n",
    "    return dataframe\n",
    "dataframe = get_dataframe(['IMG_01', 'IMG_02', 'IMG_03', 'IMG_04', 'IMG_05', \n",
    "                           'IMG_06', 'IMG_07', 'IMG_08', 'IMG_09', 'IMG_10', \n",
    "                           'IMG_11', 'IMG_12'], 'IMG_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baeada-b386-4301-bcb3-f5b17e55b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors_per_img = dataframe[dataframe['point_type']=='validation'] \n",
    "validation_errors_per_img.groupby(['img']).agg(\n",
    "    mean_error_px = ('error', lambda x: np.mean(x).round(2)),\n",
    "    mean_error_cm = ('error', lambda x: (np.mean(x)/SCALING_FACTOR*100).round(2)),\n",
    "    std_cm = ('error', lambda x: (np.std(x)/SCALING_FACTOR*100).round(2)),\n",
    "    count = ('error', 'count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdbca91-9418-4b28-88e4-5030cf8810cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([6.95, 6.93, 5.74, 9.74, 7.67, 65.13, 11.90, 34.03, 8.94, 10.19, 7.59, 8.53]).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
