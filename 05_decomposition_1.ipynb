{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b1abde-eaa4-4983-a902-f6b1dd0a955a",
   "metadata": {},
   "source": [
    "# Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac781d-4657-4116-8a83-71f15c9e8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    load_dataset,\n",
    "    get_images,\n",
    "    transform_points,\n",
    "    predict,\n",
    "    SCALING_FACTOR\n",
    ")\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764034a-d70e-4247-874b-342235b850c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/intrinsics.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "K = data['mtx']\n",
    "dist = data['dist']\n",
    "K = np.array(K)\n",
    "dist = np.array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1906ae-5454-40af-adbe-aaa4a8f01501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_position(pv_img, tv_img='IMG_00'):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    reference_pts_pv_arr = reference_pts_pv_arr[:,:2].astype(np.float32)\n",
    "    reference_pts_tv_arr = reference_pts_tv_arr[:,:2].astype(np.float32) \n",
    "\n",
    "    image_points = reference_pts_pv_arr\n",
    "    object_points = reference_pts_tv_arr\n",
    "    object_points = np.pad(\n",
    "        object_points, \n",
    "        ((0, 0), (0, 1)), \n",
    "        mode = 'constant', \n",
    "        constant_values = 0\n",
    "    )\n",
    "    \n",
    "    retval, rvec, tvec = cv2.solvePnP(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        K,\n",
    "        dist,\n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    rotM = cv2.Rodrigues(rvec)[0]\n",
    "    camera_position = np.matmul(-rotM.T, tvec) \n",
    "    return camera_position\n",
    "pos_0026 = get_camera_position('IMG_01')\n",
    "pos_0029 = get_camera_position('IMG_02')\n",
    "pos_0032 = get_camera_position('IMG_03')\n",
    "pos_0035 = get_camera_position('IMG_04')\n",
    "pos_0038 = get_camera_position('IMG_05')\n",
    "pos_0045 = get_camera_position('IMG_06')\n",
    "pos_0049 = get_camera_position('IMG_07')\n",
    "pos_0053 = get_camera_position('IMG_08')\n",
    "pos_0061 = get_camera_position('IMG_09')\n",
    "pos_0066 = get_camera_position('IMG_10')\n",
    "pos_0067 = get_camera_position('IMG_11')\n",
    "pos_0078 = get_camera_position('IMG_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a50f9-f766-4750-a924-550254304930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <> Decomposition\n",
    "pv_img = 'IMG_01'\n",
    "tv_img = 'IMG_00'\n",
    "reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "\n",
    "reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "\n",
    "h, _ = cv2.findHomography(\n",
    "    reference_pts_pv_arr,\n",
    "    reference_pts_tv_arr,\n",
    "    # method = cv2.RANSAC,\n",
    "    method = 0,\n",
    ")\n",
    "h_inv = np.linalg.inv(h)\n",
    "num, Rs, Ts, Ns  = cv2.decomposeHomographyMat(h, K)\n",
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f9caf-5532-4b90-8ea3-9f5856975571",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(validation_pts_pv_arr, h)\n",
    "plt.imshow(img_tv)\n",
    "plt.scatter(preds[:, 0], preds[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d50843-476d-43d5-b8b8-bd950c38ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.concatenate(\n",
    "    (pos_0026.T, \n",
    "     pos_0029.T, \n",
    "     pos_0032.T, \n",
    "     pos_0035.T, \n",
    "     pos_0038.T,\n",
    "     pos_0045.T,\n",
    "     pos_0049.T,\n",
    "     pos_0053.T,\n",
    "     pos_0061.T,\n",
    "     pos_0066.T,\n",
    "     pos_0067.T,\n",
    "     pos_0078.T), \n",
    "    axis=0)\n",
    "# I checked all positions manually, and they SEEM to be right! How to quantify it? \n",
    "# Height and angle we can do however.\n",
    "# FoV Maybe also for visual proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951194c-e468-4f55-b464-ce697e5eaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.arange(0, len(positions))\n",
    "labels = [\n",
    "    'IMG_01', \n",
    "    'IMG_02', \n",
    "    'IMG_03',\n",
    "    'IMG_04',\n",
    "    'IMG_05',\n",
    "    'IMG_06',\n",
    "    'IMG_07',\n",
    "    'IMG_08',\n",
    "    'IMG_09',\n",
    "    'IMG_10',\n",
    "    'IMG_11',\n",
    "    'IMG_12'\n",
    "]\n",
    "\n",
    "_, img_tv = get_images('IMG_01', 'IMG_00')\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "validation_pts_tv = load_data(f'data/annotations/IMG_00_blue.txt')\n",
    "reference_pts_tv = load_data(f'data/annotations/IMG_00_white.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aee9e2-6264-4e91-83c1-5bcf2d3e858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "img_tv = cv2.imread('data/images/IMG_00.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "# img_pv = cv2.imread('data/images/DJI_0026.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img_tv, cmap='gray', alpha=0.5)\n",
    "fc='red'\n",
    "ec='black'\n",
    "\n",
    "norm = plt.Normalize(min(colors), max(colors))\n",
    "# Use a colormap (e.g., viridis, plasma, etc.)\n",
    "colormap = plt.colormaps.get_cmap('viridis')\n",
    "\n",
    "# Plot Reference and Validation Points\n",
    "for name, pt in validation_pts_tv.items():\n",
    "    plt.scatter(pt[0], pt[1], marker='X', color='steelblue', s=120, ec='black', alpha=0.5)\n",
    "    if name in ['b8', 'b21', 'b24', 'b28']:\n",
    "        x_offset, y_offset = 0, 0\n",
    "        y_offset=200\n",
    "        if name == 'b8':\n",
    "            x_offset = 2000\n",
    "            y_offset=-500\n",
    "        if name == 'b28':\n",
    "            y_offset=-200\n",
    "            x_offset = 1000\n",
    "        if name == 'b24':\n",
    "            x_offset = 2200\n",
    "        if name == 'b21':\n",
    "            x_offset = 1000\n",
    "            y_offset = 0\n",
    "        plt.annotate(name, \n",
    "            xy=(pt[0], pt[1]),\n",
    "            #xytext=(pt[0]-700, pt[1]+200),\n",
    "            xytext=(1000+x_offset, pt[1]+y_offset),\n",
    "            color='black',\n",
    "            fontsize=14,\n",
    "            arrowprops=dict(facecolor='steelblue', shrink=0.05),\n",
    "            bbox=dict(facecolor='steelblue', edgecolor='black', boxstyle=\"round\", alpha=0.7, lw=1.0, pad=0.2)\n",
    "        )\n",
    "        \n",
    "for name, pt in reference_pts_tv.items():\n",
    "    plt.scatter(pt[0], pt[1], marker='X', color='whitesmoke', s=120, ec='black', alpha=0.5)\n",
    "    if name in ['w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w21', 'w22', 'w23', 'w26', 'w28']:\n",
    "        x_offset, y_offset = 0, 150\n",
    "        if name == 'w28':\n",
    "            x_offset = -200\n",
    "            y_offset = 150\n",
    "        if name == 'w23':\n",
    "            x_offset = -50\n",
    "            y_offset = 150\n",
    "        if name == 'w22':\n",
    "            x_offset = -50\n",
    "            y_offset = 120\n",
    "        if name == 'w9':\n",
    "            x_offset = -50\n",
    "        plt.annotate(name, \n",
    "            xy=(pt[0]+x_offset, pt[1]+y_offset),\n",
    "            # xytext=(pt[0]-700, pt[1]-200),\n",
    "            color='black',\n",
    "            fontsize=14,\n",
    "            # arrowprops=dict(facecolor='white', shrink=0.05),\n",
    "            bbox=dict(facecolor='white', edgecolor='black', boxstyle=\"round\", alpha=0.7, lw=1.0, pad=0.2)\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "# Plot each point individually with its corresponding label\n",
    "for i in range(len(positions)):\n",
    "    color = colormap(norm(colors[i]))\n",
    "    plt.scatter(positions[i, 0], positions[i, 1], color=color, label=labels[i], marker='H', s=300,\n",
    "               edgecolors='black')\n",
    "    \n",
    "\n",
    "# Create legend with unique labels\n",
    "handles, unique_labels = plt.gca().get_legend_handles_labels()\n",
    "unique_labels, unique_handles = zip(*dict(zip(unique_labels, handles)).items())\n",
    "plt.legend(unique_handles, unique_labels)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.23, 0.35),\n",
    "          ncol=2, fancybox=False, shadow=False, framealpha=1, edgecolor='black')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/camera_positions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48958b27-a9b9-411d-a04a-a774faec21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = -positions[:, -1] / SCALING_FACTOR\n",
    "for name, height in zip(labels, heights):\n",
    "    print(f'{name}: {height:.2f}m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581b94f-99af-4a92-927a-08dc85433b6a",
   "metadata": {},
   "source": [
    "### Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d3119-faa9-48ae-b99f-5157eba6fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "def get_camera_rotation(pv_img, tv_img='IMG_00'):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    reference_pts_pv_arr = reference_pts_pv_arr[:,:2].astype(np.float32)\n",
    "    reference_pts_tv_arr = reference_pts_tv_arr[:,:2].astype(np.float32) \n",
    "\n",
    "    image_points = reference_pts_pv_arr\n",
    "    object_points = reference_pts_tv_arr\n",
    "    object_points = np.pad(\n",
    "        object_points, \n",
    "        ((0, 0), (0, 1)), \n",
    "        mode = 'constant', \n",
    "        constant_values = 0\n",
    "    )\n",
    "    \n",
    "    retval, rvec, tvec = cv2.solvePnP(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        K,\n",
    "        dist\n",
    "    )\n",
    "    rotM = cv2.Rodrigues(rvec)[0]\n",
    "    camera_position = np.matmul(-rotM.T, tvec) \n",
    "\n",
    "    rotation = R.from_matrix(rotM)\n",
    "    \n",
    "    # Convert the rotation to Euler angles (assuming 'zyx' order)\n",
    "    euler_angles = rotation.as_euler('zyx', degrees=True)\n",
    "    \n",
    "    # Extract the individual angles\n",
    "    yaw, pitch, roll = euler_angles\n",
    "    return roll+90, yaw, pitch\n",
    "rot_0026 = get_camera_rotation('IMG_01')\n",
    "rot_0029 = get_camera_rotation('IMG_02')\n",
    "rot_0032 = get_camera_rotation('IMG_03')\n",
    "rot_0035 = get_camera_rotation('IMG_04')\n",
    "rot_0038 = get_camera_rotation('IMG_05')\n",
    "rot_0045 = get_camera_rotation('IMG_06')\n",
    "rot_0049 = get_camera_rotation('IMG_07')\n",
    "rot_0053 = get_camera_rotation('IMG_08')\n",
    "rot_0061 = get_camera_rotation('IMG_09')\n",
    "rot_0066 = get_camera_rotation('IMG_10')\n",
    "rot_0067 = get_camera_rotation('IMG_11')\n",
    "rot_0078 = get_camera_rotation('IMG_12')\n",
    "rotations = [rot_0026[0], rot_0029[0], rot_0032[0], rot_0035[0], rot_0038[0], rot_0045[0], rot_0049[0], rot_0053[0], rot_0061[0], rot_0066[0], rot_0078[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5cd24-8ff0-4dc9-83db-535dcbb1f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rotation in enumerate(rotations):\n",
    "    print(f'IMG_{i}: {rotation.round(1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da8cdb-02c4-4808-8628-51a1c5547e25",
   "metadata": {},
   "source": [
    "# Deomposition on my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50a0a6-894c-428a-810a-df1e5d177bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as SpicyR\n",
    "def get_pose(pv_img):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, 'IMG_00')\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    \n",
    "    h, _ = cv2.findHomography(\n",
    "        reference_pts_pv_arr,\n",
    "        reference_pts_tv_arr,\n",
    "        # method = cv2.RANSAC,\n",
    "        method = 0,\n",
    "    )\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    H = h_inv.T\n",
    "    h1 = H[0]\n",
    "    h2 = H[1]\n",
    "    h3 = H[2]\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    L = 1 / np.linalg.norm(np.dot(K_inv, h1))\n",
    "    h1, h2, h3 = h1*L, h2*L, h3*L\n",
    "    #r1 = L * np.dot(K_inv, h1)\n",
    "    #r2 = L * np.dot(K_inv, h2)\n",
    "    r1 = np.dot(K_inv, h1)\n",
    "    r2 = np.dot(K_inv, h2)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    #T = L * (K_inv @ h3.reshape(3, 1))\n",
    "    T = K_inv @ h3.reshape(3, 1)\n",
    "    R = np.array([[r1], [r2], [r3]])\n",
    "    R = np.reshape(R, (3, 3))\n",
    "    T = -R@T\n",
    "    rotation = SpicyR.from_matrix(R)\n",
    "    euler_angles = rotation.as_euler('xyz', degrees=True)\n",
    "    roll, pitch, yaw = euler_angles\n",
    "    return roll-90, T\n",
    "pitch, position = get_pose('IMG_01')\n",
    "print(pitch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
