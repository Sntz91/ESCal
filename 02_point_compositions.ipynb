{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ae2e1d-cd27-490e-9a06-67dd93858c36",
   "metadata": {},
   "source": [
    "# Point Compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4aa6c8-23eb-438c-b178-36946214cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scienceplots\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import pprint\n",
    "from shapely.geometry import Polygon\n",
    "plt.style.use(['science', 'grid', 'ieee'])\n",
    "\n",
    "from utils import (\n",
    "    load_dataset,\n",
    "    get_images,\n",
    "    transform_points,\n",
    "    get_densities,\n",
    "    predict,\n",
    "    calculate_errors,\n",
    "    get_result_dict,\n",
    "    SCALING_FACTOR,\n",
    "    plot_setup, \n",
    "    plot_setup_noised,\n",
    "    plot_predictions,\n",
    "    add_outlier\n",
    ")\n",
    "\n",
    "def filter_points(points, keys):\n",
    "    filtered = {key: points[key] for key in keys}\n",
    "    return filtered\n",
    "\n",
    "def conduct_experiment(pv_img, tv_img, plot=True, print_errors=True, used_ref_points=None, return_homography=False):\n",
    "    # Load Data\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "    \n",
    "    if used_ref_points:\n",
    "        reference_pts_pv = filter_points(reference_pts_pv, used_ref_points)\n",
    "        reference_pts_tv = filter_points(reference_pts_tv, used_ref_points)\n",
    "        \n",
    "    # Transform Points to Homogeneous Numpy arrays\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    # Calculate Homography\n",
    "    h, _ = cv2.findHomography(\n",
    "        reference_pts_pv_arr,\n",
    "        reference_pts_tv_arr,\n",
    "        # method = cv2.RANSAC,\n",
    "        method = 0,\n",
    "    )\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    # Get Pixel Densities\n",
    "    reference_densities = get_densities(reference_pts_tv_arr, h_inv)\n",
    "    validation_densities = get_densities(validation_pts_tv_arr, h_inv)\n",
    "    \n",
    "    # Predict Points\n",
    "    predicted_reference_pts_tv = predict(reference_pts_pv_arr, h)\n",
    "    predicted_validation_pts_tv = predict(validation_pts_pv_arr, h)\n",
    "    \n",
    "    # Errors\n",
    "    reference_errors = calculate_errors(predicted_reference_pts_tv, reference_pts_tv_arr)\n",
    "    validation_errors = calculate_errors(predicted_validation_pts_tv, validation_pts_tv_arr)\n",
    "\n",
    "    # Combine Results in Dictionary\n",
    "    reference_result_dict = get_result_dict(reference_pts_pv, reference_pts_tv_arr, predicted_reference_pts_tv, reference_errors, reference_densities, reference_pts_pv_arr)\n",
    "    validation_result_dict = get_result_dict(validation_pts_pv, validation_pts_tv_arr, predicted_validation_pts_tv, validation_errors, validation_densities, reference_pts_pv_arr)\n",
    "    \n",
    "    # Print Errors\n",
    "    if print_errors:\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) :.2f} PX!')\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "        print('---')\n",
    "        print(f'Validation Error: {np.mean(validation_errors):.2f} PX!')\n",
    "        print(f'Validation Error: {np.mean(validation_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "    \n",
    "    # Plots\n",
    "    if plot:\n",
    "        plot_setup(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "        plot_predictions(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "    if return_homography:\n",
    "        return reference_result_dict, validation_result_dict, h\n",
    "    return reference_result_dict, validation_result_dict\n",
    "\n",
    "def get_collinearity_score(subset, reference_pts_pv):\n",
    "    A = np.array(reference_pts_pv[subset[0]])\n",
    "    B = np.array(reference_pts_pv[subset[1]])\n",
    "    C = np.array(reference_pts_pv[subset[2]])\n",
    "    AB = np.linalg.norm(A-B) \n",
    "    AC = np.linalg.norm(A-C) \n",
    "    BC = np.linalg.norm(B-C)\n",
    "    distances = sorted([AB, AC, BC])\n",
    "    return (distances[0] + distances[1] - distances[2]) / distances[2] * 100\n",
    "    \n",
    "def get_overall_collinearity_score(used_ref_pts, reference_pts_pv):\n",
    "    scores = []\n",
    "    for subset in combinations(used_ref_pts, 3):\n",
    "        score = get_collinearity_score(subset, reference_pts_pv)\n",
    "        scores.append(score)\n",
    "    return min(scores)\n",
    "\n",
    "def get_collinearity_scores(used_ref_pts, reference_pts_pv):\n",
    "    scores = []\n",
    "    for subset in combinations(used_ref_pts, 3):\n",
    "        score = get_collinearity_score(subset, reference_pts_pv)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d863588-45f7-4949-b399-1bd99682aac7",
   "metadata": {},
   "source": [
    "## How Many Points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345156e6-3233-429b-8bb1-d1037034639f",
   "metadata": {},
   "source": [
    "Using four points is enough to determine a homography matrix $\\mathrm{H}$. However, as we have noise, we can use more points and create an overdetermined system of linear equations. Then, we can use an optimization technique to calculate $\\mathrm{H}$.\n",
    "\n",
    "How many points should we use? Let's see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a56a8-f264-4613-8795-8f7c9bf490e4",
   "metadata": {},
   "source": [
    "Let's consider image DJI_0026 and test various point compositions of **four**, **five**, **six**, **seven**, **eight**, **nine** reference points. Let's start by doing the experiments completely random, and then filter degenerate solutions; see **2.2.1 Collinearity**. To confirm our conclusion, do the same experiment for DJI_0029."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3edb81-62ae-4231-9c44-357cf59fca48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def n_point_experiment(pv_img, tv_img):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    all_reference_points = list(reference_pts_pv.keys())\n",
    "\n",
    "    rows = []\n",
    "    # For all reference point combinations with k=4\n",
    "    for k in range(4, len(all_reference_points)+1):\n",
    "        print('---'*10, k, '--'*10)\n",
    "        for i, subset in enumerate(combinations(all_reference_points, k)):\n",
    "            print('#'*10)\n",
    "            print(f'Experiment {i}')\n",
    "            # Conduct Experiment\n",
    "            reference_result_dict, validation_result_dict = conduct_experiment(pv_img, tv_img, used_ref_points=subset, plot=False)\n",
    "\n",
    "            spanning_points = []\n",
    "            for ref_pt_name in subset:\n",
    "                spanning_points.append(reference_pts_pv[ref_pt_name])\n",
    "            polygon = Polygon(spanning_points)\n",
    "            spanned_area = polygon.area / (4000*3000) * 100\n",
    "    \n",
    "            # Make resulting Dict \n",
    "            collinearity_score = get_overall_collinearity_score(subset, reference_pts_pv)\n",
    "            collinearity_scores = get_collinearity_scores(subset, reference_pts_pv)\n",
    "            for pt, pt_dict in validation_result_dict.items():\n",
    "                pt_dict['k'] = k\n",
    "                pt_dict['experiment'] = i\n",
    "                pt_dict['name'] = pt\n",
    "                pt_dict['collinearity'] = collinearity_score\n",
    "                pt_dict['collinearity_scores'] = collinearity_scores\n",
    "                pt_dict['used_ref_pts'] = subset\n",
    "                pt_dict['spanned_area'] = spanned_area\n",
    "                rows.append(pt_dict)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['img'] = pv_img\n",
    "    return df\n",
    "n_pt_results = n_point_experiment('IMG_01', 'IMG_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5a2fe-09cf-4bc0-b129-304488e96895",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)#, figsize=(12, 10))\n",
    "n_pt_results.boxplot(\n",
    "    column='error',\n",
    "    by='k',\n",
    "    showfliers=True,\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgray', lw=1),\n",
    "    medianprops=dict(color='black', lw=2),\n",
    "    whiskerprops = dict(color = \"black\", lw=1),\n",
    "    widths=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c070-0700-4281-af39-acceb4db88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = n_pt_results.loc[((n_pt_results['collinearity'] >= 1) & (n_pt_results['k'] == 4)) | (n_pt_results['k'] != 4)] # TODO!\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "inliers.boxplot(\n",
    "    column='error',\n",
    "    by='k',\n",
    "    showfliers=True,\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgray', lw=1),\n",
    "    medianprops=dict(color='black', lw=2),\n",
    "    whiskerprops = dict(color = \"black\", lw=1),\n",
    "    widths=0.5,\n",
    "    ax=ax1\n",
    ")\n",
    "inliers.boxplot(\n",
    "    column='error',\n",
    "    by='k',\n",
    "    showfliers=False,\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgray', lw=1),\n",
    "    medianprops=dict(color='black', lw=2),\n",
    "    whiskerprops = dict(color = \"black\", lw=1),\n",
    "    widths=0.5,\n",
    "    ax=ax2\n",
    ")\n",
    "fig.suptitle('')\n",
    "ax1.set_title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2563c-3b50-45fd-a07d-1045af74a012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inliers = n_pt_results.loc[((n_pt_results['collinearity'] >= 1) & (n_pt_results['k'] == 4)) | (n_pt_results['k'] != 4)] # TODO!\n",
    "fig, ax1 = plt.subplots(1, 1)#, figsize=(10, 10))\n",
    "inliers.boxplot(\n",
    "    column='error',\n",
    "    by='k',\n",
    "    showfliers=False,\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgray', lw=.8),\n",
    "    medianprops=dict(color='black', lw=1),\n",
    "    whiskerprops = dict(color = \"black\", lw=.8),\n",
    "    widths=0.5,\n",
    "    ax=ax1\n",
    ")\n",
    "fig.suptitle('')\n",
    "ax1.set_title('error [px]')\n",
    "# ax1.set_xlabel('error [px]')\n",
    "ax1.set_ylabel('number of reference points $k$')\n",
    "\n",
    "t1 = ax1.text(13.5, 1.3, 'Outlier until $122.6$', fontsize=6)\n",
    "t1.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black', lw=.5))\n",
    "t2 = ax1.text(13.5, 1.97, 'Outlier until $75.8$', fontsize=6)\n",
    "t2.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black', lw=.5))\n",
    "t3 = ax1.text(13.5, 2.97, 'Outlier until $35.7$', fontsize=6)\n",
    "t3.set_bbox(dict(facecolor='white', alpha=1, edgecolor='black', lw=.5))\n",
    "plt.grid(False)\n",
    "plt.savefig('output/boxplot_errors_by_k_filtered.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf7b6a-6c33-457b-976c-4969e65db4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collinearity scores with k=5??\n",
    "fives = n_pt_results.loc[n_pt_results['k'] == 5]\n",
    "fives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a30d8-e9f5-4f3f-a82d-601e336bf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fives.plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=100,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.8,\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415267c4-57d1-43f5-8237-3fdb5b169231",
   "metadata": {},
   "outputs": [],
   "source": [
    "fives.plot.scatter(\n",
    "    x='spanned_area', \n",
    "    y='error',\n",
    "    s=100,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.8,\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b297e-e4c6-42b7-956d-82fca93f9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers.plot.scatter(\n",
    "    x='spanned_area', \n",
    "    y='error',\n",
    "    s=100,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.8,\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.savefig('scatter_error_by_area_distance.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d95cf-fc39-423b-b919-7ba6a3faa03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers_spanned_area = inliers.loc[inliers['spanned_area'] >= 10] \n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "inliers_spanned_area.boxplot(\n",
    "    column='error',\n",
    "    by='k',\n",
    "    showfliers=True,\n",
    "    vert=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightgray', lw=1),\n",
    "    medianprops=dict(color='black', lw=2),\n",
    "    whiskerprops = dict(color = \"black\", lw=1),\n",
    "    widths=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
