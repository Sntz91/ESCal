{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c4394f-8128-49c1-bc67-974169b92183",
   "metadata": {},
   "source": [
    "# How to spread points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd557ae-3901-4a45-917b-d8bd39a78a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scienceplots\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import pprint\n",
    "from shapely.geometry import Polygon\n",
    "plt.style.use(['science', 'grid', 'ieee'])\n",
    "\n",
    "from utils import (\n",
    "    load_dataset,\n",
    "    get_images,\n",
    "    transform_points,\n",
    "    get_densities,\n",
    "    predict,\n",
    "    calculate_errors,\n",
    "    get_result_dict,\n",
    "    SCALING_FACTOR,\n",
    "    plot_setup, \n",
    "    plot_setup_noised,\n",
    "    plot_predictions,\n",
    "    add_outlier\n",
    ")\n",
    "\n",
    "def filter_points(points, keys):\n",
    "    filtered = {key: points[key] for key in keys}\n",
    "    return filtered\n",
    "\n",
    "def conduct_experiment(pv_img, tv_img, plot=True, print_errors=True, used_ref_points=None, return_homography=False):\n",
    "    # Load Data\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    img_pv, img_tv = get_images(pv_img, tv_img)\n",
    "    \n",
    "    if used_ref_points:\n",
    "        reference_pts_pv = filter_points(reference_pts_pv, used_ref_points)\n",
    "        reference_pts_tv = filter_points(reference_pts_tv, used_ref_points)\n",
    "        \n",
    "    # Transform Points to Homogeneous Numpy arrays\n",
    "    reference_pts_pv_arr, reference_pts_tv_arr, validation_pts_pv_arr, validation_pts_tv_arr = transform_points(\n",
    "        reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv)\n",
    "    # Calculate Homography\n",
    "    h, _ = cv2.findHomography(\n",
    "        reference_pts_pv_arr,\n",
    "        reference_pts_tv_arr,\n",
    "        # method = cv2.RANSAC,\n",
    "        method = 0,\n",
    "    )\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    # Get Pixel Densities\n",
    "    reference_densities = get_densities(reference_pts_tv_arr, h_inv)\n",
    "    validation_densities = get_densities(validation_pts_tv_arr, h_inv)\n",
    "    \n",
    "    # Predict Points\n",
    "    predicted_reference_pts_tv = predict(reference_pts_pv_arr, h)\n",
    "    predicted_validation_pts_tv = predict(validation_pts_pv_arr, h)\n",
    "    \n",
    "    # Errors\n",
    "    reference_errors = calculate_errors(predicted_reference_pts_tv, reference_pts_tv_arr)\n",
    "    validation_errors = calculate_errors(predicted_validation_pts_tv, validation_pts_tv_arr)\n",
    "\n",
    "    # Combine Results in Dictionary\n",
    "    reference_result_dict = get_result_dict(reference_pts_pv, reference_pts_tv_arr, predicted_reference_pts_tv, reference_errors, reference_densities, reference_pts_pv_arr)\n",
    "    validation_result_dict = get_result_dict(validation_pts_pv, validation_pts_tv_arr, predicted_validation_pts_tv, validation_errors, validation_densities, reference_pts_pv_arr)\n",
    "    \n",
    "    # Print Errors\n",
    "    if print_errors:\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) :.2f} PX!')\n",
    "        print(f'Reference  Error: {np.mean(reference_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "        print('---')\n",
    "        print(f'Validation Error: {np.mean(validation_errors):.2f} PX!')\n",
    "        print(f'Validation Error: {np.mean(validation_errors) / SCALING_FACTOR * 100 :.2f} CM!')\n",
    "    \n",
    "    # Plots\n",
    "    if plot:\n",
    "        plot_setup(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "        plot_predictions(img_tv, img_pv, reference_result_dict, validation_result_dict)\n",
    "    if return_homography:\n",
    "        return reference_result_dict, validation_result_dict, h\n",
    "    return reference_result_dict, validation_result_dict\n",
    "\n",
    "def get_collinearity_score(subset, reference_pts_pv):\n",
    "    A = np.array(reference_pts_pv[subset[0]])\n",
    "    B = np.array(reference_pts_pv[subset[1]])\n",
    "    C = np.array(reference_pts_pv[subset[2]])\n",
    "    AB = np.linalg.norm(A-B) \n",
    "    AC = np.linalg.norm(A-C) \n",
    "    BC = np.linalg.norm(B-C)\n",
    "    distances = sorted([AB, AC, BC])\n",
    "    return (distances[0] + distances[1] - distances[2]) / distances[2] * 100\n",
    "    \n",
    "def get_overall_collinearity_score(used_ref_pts, reference_pts_pv):\n",
    "    scores = []\n",
    "    for subset in combinations(used_ref_pts, 3):\n",
    "        score = get_collinearity_score(subset, reference_pts_pv)\n",
    "        scores.append(score)\n",
    "    return min(scores)\n",
    "\n",
    "def get_collinearity_scores(used_ref_pts, reference_pts_pv):\n",
    "    scores = []\n",
    "    for subset in combinations(used_ref_pts, 3):\n",
    "        score = get_collinearity_score(subset, reference_pts_pv)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5220c4-6adc-4ae0-8e71-0e4de4d6f772",
   "metadata": {},
   "source": [
    "Let's examine the case for four reference points, as they are the minimum required. We have determined the following possible influencing factors:\n",
    "1. Collinearity\n",
    "2. Distance to next reference point\n",
    "3. Pixel Density\n",
    "4. Spanned Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e936b-8df4-47fc-ab4b-28201c0522ce",
   "metadata": {},
   "source": [
    "## 1. Collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb30dcd-9ee2-49b1-bc1e-ab6728b871c0",
   "metadata": {},
   "source": [
    "**Conclusion**: Being almost collinear has some fatal consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701faac-9da9-4c2a-8153-e35041e3bb83",
   "metadata": {},
   "source": [
    "We need at least four points to determine a homography $\\mathrm{H}$. It collapses when at least three points are collinear. In the real world, points are rarely collinear. However, we can quantify collinearity with the following measurement:\n",
    "\n",
    "Given three points A, B, C and their corresponding edges a, b, c, let's calculate the following measure\n",
    "$$\n",
    "\\text{collinearity} = (a + b - c) / c,\n",
    "$$\n",
    "where $c$ is the longest distance. Hence, given four reference points, we can determine $\\begin{pmatrix} 4 \\\\ 3 \\end{pmatrix} = 4$ collinearity scores. To quantify the collinearity score for the whole four reference point setup, we will take the smallest collinearity score. Note that this only works for four reference points. With more reference points, we might need to adjust it, as the homography has more chance to overcome the collinearity. INSERT MATH HERE FOR REFERENCE POINT SETUP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598a73-874c-4881-b37f-2c6281020318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Functions\n",
    "def plot_reference_point(name, x, y, ax, fc='white', ec='black', x_offset=-50, y_offset=0):\n",
    "    ax.plot(x, y, marker='X', markersize=8, color='whitesmoke')\n",
    "    ax.annotate(name, \n",
    "        xy=(x, y),\n",
    "        color='black',\n",
    "        fontsize=14,\n",
    "        bbox=dict(facecolor=fc, edgecolor=ec, boxstyle=\"round\", alpha=0.8, lw=1.5, pad=0.5)\n",
    "    )\n",
    "    \n",
    "def plot_reference_points(reference_pts_pv, ax):\n",
    "    for name, pt in reference_pts_pv.items(): \n",
    "        plot_reference_point(name, pt[0], pt[1], ax)\n",
    "\n",
    "def plot_collinearity_score(R1, R2, R3, reference_pts_pv, ax, fc, ec):\n",
    "    score = get_collinearity_score([R1, R2, R3], reference_pts_pv)\n",
    "    A = reference_pts_pv[R1]\n",
    "    B = reference_pts_pv[R2]\n",
    "    C = reference_pts_pv[R3] \n",
    "\n",
    "    # Plot lines\n",
    "    ax.plot([A[0], B[0], C[0]], [A[1], B[1], C[1]], lw=3, linestyle='--', color=fc)\n",
    "    # Plot Score\n",
    "    plot_reference_point(f'{score:.2f}', B[0]+50, B[1]-100, ax, 'white', ec)\n",
    "    # Plot Reference points\n",
    "    for name, pt in [(R1, A), (R2, B), (R3, C)]:\n",
    "        plot_reference_point(name, pt[0], pt[1], ax, fc, ec)\n",
    "\n",
    "\n",
    "def plot_collinearity_score_offset(R1, R2, R3, reference_pts_pv, ax, fc, ec, offset):\n",
    "    score = get_collinearity_score([R1, R2, R3], reference_pts_pv)\n",
    "    A = list(reference_pts_pv[R1])\n",
    "    B = list(reference_pts_pv[R2])\n",
    "    C = list(reference_pts_pv[R3])\n",
    "\n",
    "    A[0] = A[0] + offset[0]\n",
    "    B[0] = B[0] + offset[0]\n",
    "    C[0] = C[0] + offset[0]\n",
    "    \n",
    "    A[1] = A[1] + offset[1]\n",
    "    B[1] = B[1] + offset[1]\n",
    "    C[1] = C[1] + offset[1]\n",
    "\n",
    "    # Plot lines\n",
    "    ax.plot([A[0], B[0], C[0]], [A[1], B[1], C[1]], lw=3, linestyle='dotted', color=fc)\n",
    "    # Plot Score\n",
    "    plot_reference_point(f'{score:.2f}', B[0]+0, B[1]-190, ax, 'white', fc)\n",
    "    # Plot Reference points\n",
    "    for name, pt in [(R1, A), (R2, B), (R3, C)]:\n",
    "        plot_reference_point(name, pt[0], pt[1], ax, fc, ec)\n",
    "\n",
    "def plot_used_reference_points(ref_pts, reference_pts_pv, ax):\n",
    "    for name, pt in reference_pts_pv.items():\n",
    "        if name not in ref_pts:\n",
    "            continue\n",
    "        plot_reference_point(name, pt[0], pt[1], ax, 'salmon', 'red')\n",
    "        \n",
    "# Necessary Variables\n",
    "pv_img_fname = 'IMG_01'\n",
    "tv_img_fname = 'IMG_00'\n",
    "\n",
    "pv_img, tv_img = get_images(pv_img_fname, tv_img_fname)\n",
    "reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img_fname, tv_img_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1023d36-0c0a-40bf-b142-e1f4b95b12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual collinearity scores\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "\n",
    "ax.imshow(pv_img, alpha=0.1)\n",
    "ax.axis('off')\n",
    "\n",
    "# plot_reference_points(reference_pts_pv, ax)\n",
    "plot_collinearity_score_offset('w8', 'w9', 'w19', reference_pts_pv, ax, 'steelblue', 'royalblue', [100, 100])\n",
    "plot_collinearity_score_offset('w4', 'w5', 'w7', reference_pts_pv, ax, 'salmon', 'tomato', [0, 0])\n",
    "plot_collinearity_score_offset('w7', 'w6', 'w8', reference_pts_pv, ax, 'mediumseagreen', 'seagreen', [50, 50])\n",
    "\n",
    "plt.savefig('output/collinearity_examples.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74346e56-f8bf-4bfc-ba23-89749aee9114",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot Combined Collinarity score\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "ax.imshow(pv_img)\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plot_reference_points(reference_pts_pv, ax)\n",
    "used_reference_points = ['w4', 'w5', 'w7', 'w8']\n",
    "plot_used_reference_points(used_reference_points, reference_pts_pv, ax)\n",
    "collinearity_score = get_overall_collinearity_score(used_reference_points, reference_pts_pv)\n",
    "print(f'collinearity score: {collinearity_score:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0d57d-8ddd-4fa9-86c4-cbd13d34825a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_collinearity_scores_new(used_ref_pts, reference_pts_pv):\n",
    "    scores = []\n",
    "    for subset in combinations(used_ref_pts, 3):\n",
    "        score = get_collinearity_score(subset, reference_pts_pv)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "all_reference_pts = list(reference_pts_pv.keys())\n",
    "result = {}\n",
    "for subset in combinations(all_reference_pts, 3):\n",
    "    score = get_collinearity_scores_new(subset, reference_pts_pv)\n",
    "    result[subset] = score\n",
    "result = {k: v for k, v in sorted(result.items(), key=lambda item: item[1])}\n",
    "pprint.pp(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b317b-f0cf-4946-981f-874f45476f13",
   "metadata": {},
   "source": [
    "Now that the collinearity score seems to work, let's examine how it affects the results. We will use every possible combination of four reference points to calculate $\\mathrm{H}$ and determine the collinearity score and the error. Then we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf2505-ec87-4604-88d6-d01f637ecdb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_points(points, keys):\n",
    "    filtered = {key: points[key] for key in keys}\n",
    "    return filtered\n",
    "\n",
    "def collinearity_experiment(pv_img, tv_img):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    all_reference_points = list(reference_pts_pv.keys())\n",
    "\n",
    "    rows = []\n",
    "    k=4\n",
    "    # For all reference point combinations with k=4\n",
    "    for i, subset in enumerate(combinations(all_reference_points, k)):\n",
    "        print('#'*10)\n",
    "        print(f'Experiment {i}')\n",
    "        # Conduct Experiment\n",
    "        reference_result_dict, validation_result_dict = conduct_experiment(pv_img, tv_img, used_ref_points=subset, plot=False)\n",
    "\n",
    "        # Make resulting Dict \n",
    "        collinearity_score = get_overall_collinearity_score(subset, reference_pts_pv)\n",
    "        for pt, pt_dict in validation_result_dict.items():\n",
    "            pt_dict['k'] = 4\n",
    "            pt_dict['experiment'] = i\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['collinearity'] = collinearity_score\n",
    "            pt_dict['used_ref_pts'] = subset\n",
    "            rows.append(pt_dict)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['img'] = pv_img\n",
    "    return df\n",
    "\n",
    "result_df = collinearity_experiment('IMG_01', tv_img_fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a202c90-0844-4ba7-a72c-7564d9b49b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "result_df.plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=200,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.7,\n",
    "    ax=ax1\n",
    ")\n",
    "result_df.loc[result_df['collinearity'] > 1].plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=200,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.7,\n",
    "    ax=ax2\n",
    ")\n",
    "# plt.savefig('collinearity_error.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fcb5f-288d-4048-ad45-33624e566195",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)#, figsize=(12, 10))\n",
    "\n",
    "result_df.plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=10,\n",
    "   # c='#FDE725FF',\n",
    "     c='#440154FF',\n",
    "    # colormap='viridis',\n",
    "    alpha=0.5,\n",
    "    ax=ax1\n",
    ")\n",
    "result_df.loc[result_df['collinearity'] > 1].plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=10,\n",
    "    #c='#440154FF',\n",
    "    c='#22A884FF',\n",
    "    # colormap='viridis',\n",
    "    alpha=0.5,\n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "ax1.set_ylabel('error [px]')\n",
    "ax2.set_ylabel('error [px]')\n",
    "ax2.set_xlabel('collinearity score')\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.savefig('output/collinearity_error.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52c164-0183-4be0-bd79-d7813f78135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = result_df.loc[result_df['collinearity'] < 1]\n",
    "inliers = result_df.loc[result_df['collinearity'] >=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d304fda-a586-42e4-a13a-8842449093e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_keys = outliers['used_ref_pts'].unique()\n",
    "\n",
    "print('-----'*20)\n",
    "print(f'Get rid of the following {len(outlier_keys)} Homographies with a collinearity score < 1:')\n",
    "print('-----'*20)\n",
    "pprint.pp(outlier_keys)\n",
    "print('-----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a78eae-e1e2-43fc-85ed-67b7aa53c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.groupby(['experiment', 'used_ref_pts']).agg(\n",
    "    mean=('error', lambda x: np.mean(x).round(2)),\n",
    "    min=('error', lambda x: np.min(x).round(2)),\n",
    "    max=('error', lambda x: np.max(x).round(2)),\n",
    "    collinearity_score=('collinearity', lambda x: np.min(x).round(2))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2978e-5cad-4e3e-9712-c7dbc2931fe6",
   "metadata": {},
   "source": [
    "What's the average score of the inliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424567d3-ff84-4a8e-b227-d9cdcdf82388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean inlier error: {inliers[\"error\"].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1b2c6-e1e0-4f26-b22f-09c67d5aba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers.plot.scatter(\n",
    "    x='collinearity', \n",
    "    y='error',\n",
    "    s=100,\n",
    "    c='pixel_density',\n",
    "    colormap='viridis',\n",
    "    alpha=0.8,\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57435442-5902-4593-b7d1-0809e1f1c5c8",
   "metadata": {},
   "source": [
    "## 2. Distance to next Reference Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ba0a3-9e95-41f9-90de-40ed6164d78a",
   "metadata": {},
   "source": [
    "**Conclusion**: Of course it influences the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83e729-f08c-4db0-9330-38a78b5aaf24",
   "metadata": {},
   "source": [
    "When a reference point was actually used, then of course near points should perform better, as the $Z$ Coordinate should **usually** be similar. When we use more than four points to calculate $\\mathrm{H}$, then it is at least considered, however, depending on the used optimization technique. You will see an image about this under **4 Spanned Area**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530360a-3583-4318-aeb9-414560717f59",
   "metadata": {},
   "source": [
    "## 3. Pixel Density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d02fd-374d-438c-ab02-eb61a0e75337",
   "metadata": {},
   "source": [
    "**Conclusion:** It seems to really have some minor influence, but of course it's only one of many. I think it will have much more influence when we make the noise experiments, as we calculate the distance within the top view. See later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c633e78-ca9d-42a6-8f55-ea37c109a5a7",
   "metadata": {},
   "source": [
    "Validation Points that lie further away from the camera position have less pixels available around it, such that being a single pixel off, results in a higher error for the validation point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552aad2-f49c-45eb-9772-ca6cd8d855f7",
   "metadata": {},
   "source": [
    "We can quantify pixel density as follows: Consider four points around the respective validation point within the top view, each one meter away in the x and y direction (positive and negative). The resulting four surrounding points can be transformed into the perspective view using the Homography $\\mathrm{H}^{-1}$. We then average the distances between the points and the validation point within the perspective view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5e79c-3b1c-44a2-a0a3-ad6510b6c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Setup\n",
    "pv_img_fname = 'IMG_02'\n",
    "tv_img_fname = 'IMG_00'\n",
    "\n",
    "pv_img, tv_img = get_images(pv_img_fname, tv_img_fname)\n",
    "reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img_fname, tv_img_fname)\n",
    "reference_result_dict, validation_result_dict = conduct_experiment('IMG_02', tv_img_fname, plot=False, print_errors=False)\n",
    "\n",
    "plot_setup(tv_img, pv_img, reference_result_dict, validation_result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c68a5ca-c46a-44a2-8128-fb9a672b3ce4",
   "metadata": {},
   "source": [
    "Now let's see if this has some influence on our results. Hence, we will calculate the homography matrix for every image using all reference points (no outliers) and then plot the errors of each validation points against the pixel density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32689900-846c-43b6-8690-6497e8707161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(pv_imgs, tv_img):\n",
    "    dataframe = pd.DataFrame()\n",
    "    rows = []\n",
    "    for pv_img in pv_imgs:\n",
    "        print(pv_img)\n",
    "        reference_result_dict, validation_result_dict = conduct_experiment(pv_img, tv_img, plot=False, print_errors=False)\n",
    "        for pt, pt_dict in reference_result_dict.items():\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['img'] = pv_img\n",
    "            pt_dict['point_type'] = 'reference'\n",
    "            rows.append(pt_dict) \n",
    "        for pt, pt_dict in validation_result_dict.items():\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['img'] = pv_img\n",
    "            pt_dict['point_type'] = 'validation' \n",
    "            rows.append(pt_dict) \n",
    "    dataframe = pd.DataFrame(rows)  \n",
    "    return dataframe\n",
    "\n",
    "dataframe = get_dataframe(['IMG_01', 'IMG_02', 'IMG_03', 'IMG_04', 'IMG_05', \n",
    "                           'IMG_06', 'IMG_07', 'IMG_08', 'IMG_09', 'IMG_10', \n",
    "                           'IMG_11', 'IMG_12'], 'IMG_00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffbd21-b094-4077-8b21-ca89b9c9ccfd",
   "metadata": {},
   "source": [
    "Overall Error Distribution per image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc8897-d68d-4efa-b528-a3565fdcf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors_per_img = dataframe[dataframe['point_type']=='validation'] \n",
    "validation_errors_per_img.boxplot(column='error', by='img', \n",
    "                                  vert=False, \n",
    "                                  patch_artist=True, \n",
    "                                  boxprops=dict(facecolor='lightgray', lw=1), \n",
    "                                  medianprops=dict(color='black', lw=2),\n",
    "                                  whiskerprops = dict(color = \"black\", lw=1),\n",
    "                                  widths=0.5,\n",
    "                                  figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031939fd-c73c-40c3-b649-799c4ac707f8",
   "metadata": {},
   "source": [
    "Now how about pixel densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67132d37-9933-40ef-b9ab-633dbbd6650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHERE IS THE 2K??!\n",
    "# COLOR PER IMAGE WOULD BE NICE\n",
    "image_color_dict = {\n",
    "    'IMG_01':1,  \n",
    "    'IMG_02':2, \n",
    "    'IMG_03':3,  \n",
    "    'IMG_04':4,  \n",
    "    'IMG_05':5, \n",
    "    'IMG_06':6, \n",
    "    'IMG_07':7, \n",
    "    'IMG_08':8, \n",
    "    'IMG_09':9, \n",
    "     'IMG_10':10,\n",
    "     'IMG_11':11,\n",
    "     'IMG_12':12\n",
    "}\n",
    "\n",
    "validation_errors_per_img['color'] = validation_errors_per_img.apply(lambda x: image_color_dict[x['img']], axis=1)\n",
    "validation_errors_per_img.plot.scatter(x='pixel_density',\n",
    "                y='error',\n",
    "                c='color',\n",
    "                # s='distance_to_next_ref_pt', # TODO\n",
    "                colormap='viridis',\n",
    "                alpha=0.8,\n",
    "                figsize=(15, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc585c8-5a74-4c0e-997f-9e5e7ac89e98",
   "metadata": {},
   "source": [
    "Where is the 2000 density outlier? Validaiton point **b1** in **DJI_0053**. Let's get rid of him, s.t. we can see the plot better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d83a89-fab6-4a8a-8fad-32e8dc8e35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors_per_img_wo_outlier = validation_errors_per_img.loc[validation_errors_per_img['pixel_density'] < 1000]\n",
    "validation_errors_per_img_wo_outlier.plot.scatter(x='pixel_density',\n",
    "                y='error',\n",
    "                c='color',\n",
    "                # s='distance_to_next_ref_pt', # TODO\n",
    "                colormap='viridis',\n",
    "                alpha=0.8,\n",
    "                figsize=(15, 10)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6953f5-e879-4ad3-b7a4-861f214d63ed",
   "metadata": {},
   "source": [
    "## Spanned Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cb144-f8ad-42be-aace-1cefde91a730",
   "metadata": {},
   "source": [
    "**Conclusion:** The spanned area correlates strongly with the distance to the next reference point. This influences the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347a76e-108e-4596-ad8f-0519e297ec69",
   "metadata": {},
   "source": [
    "The bigger the spanned area, the more we average over the whole scene and can take more area into account. This strongly correlates to the distance to the next reference point of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e23ea7-7755-4f15-87fc-e312cd46decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Setup\n",
    "pv_img_fname = 'IMG_01'\n",
    "tv_img_fname = 'IMG_00'\n",
    "\n",
    "pv_img, tv_img = get_images(pv_img_fname, tv_img_fname)\n",
    "reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img_fname, tv_img_fname)\n",
    "reference_result_dict, validation_result_dict = conduct_experiment('IMG_00', tv_img_fname, plot=False, print_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417e91d-54ff-4c3c-a23f-666e04e8e754",
   "metadata": {},
   "source": [
    "Let's conduct the experiment with four reference points, but filter the collinear homographies for one specific image, e.g., DJI_0026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849d333-9f58-4f99-a9ff-cccf234cd95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_points(points, keys):\n",
    "    filtered = {key: points[key] for key in keys}\n",
    "    return filtered\n",
    "\n",
    "def collinearity_experiment(pv_img, tv_img):\n",
    "    reference_pts_pv, reference_pts_tv, validation_pts_pv, validation_pts_tv = load_dataset(pv_img, tv_img)\n",
    "    all_reference_points = list(reference_pts_pv.keys())\n",
    "\n",
    "    rows = []\n",
    "    k=4\n",
    "    # For all reference point combinations with k=4\n",
    "    for i, subset in enumerate(combinations(all_reference_points, k)):\n",
    "        print('#'*10)\n",
    "        print(f'Experiment {i}')\n",
    "        # Conduct Experiment\n",
    "        reference_result_dict, validation_result_dict = conduct_experiment(pv_img, tv_img, used_ref_points=subset, plot=False)\n",
    "\n",
    "        # Make resulting Dict \n",
    "        collinearity_score = get_overall_collinearity_score(subset, reference_pts_pv)\n",
    "        spanning_points = []\n",
    "        for ref_pt_name in subset:\n",
    "            spanning_points.append(reference_pts_pv[ref_pt_name])\n",
    "        polygon = Polygon(spanning_points)\n",
    "        spanned_area = polygon.area / (4000*3000) * 100\n",
    "        for pt, pt_dict in validation_result_dict.items():\n",
    "            pt_dict['k'] = 4\n",
    "            pt_dict['experiment'] = i\n",
    "            pt_dict['name'] = pt\n",
    "            pt_dict['collinearity'] = collinearity_score\n",
    "            pt_dict['used_ref_pts'] = subset\n",
    "            pt_dict['spanned_area'] = spanned_area\n",
    "            rows.append(pt_dict)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['img'] = pv_img\n",
    "    return df\n",
    "\n",
    "result_df = collinearity_experiment('IMG_01', tv_img_fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49639e26-139d-434b-a1c0-68d89a05da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example area and the area score.\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))\n",
    "ax1.imshow(pv_img)\n",
    "ax1.axis('off')\n",
    "ax2.imshow(pv_img)\n",
    "ax2.axis('off')\n",
    "plot_reference_points(reference_pts_pv, ax1)\n",
    "plot_reference_points(reference_pts_pv, ax2)\n",
    "\n",
    "used_reference_points = ['w4', 'w8', 'w5', 'w6']\n",
    "plot_used_reference_points(used_reference_points, reference_pts_pv, ax1)\n",
    "area = result_df.loc[result_df['used_ref_pts'] == tuple(used_reference_points)]['spanned_area'].values[0]\n",
    "print(f'Area: {area:.2f}')\n",
    "\n",
    "used_reference_points = ['w19', 'w21', 'w22', 'w9']\n",
    "plot_used_reference_points(used_reference_points, reference_pts_pv, ax2)\n",
    "area = result_df.loc[result_df['used_ref_pts'] == tuple(used_reference_points)]['spanned_area'].values[0]\n",
    "print(f'Area: {area:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d805ea-89db-444b-a16a-6a8baf2268fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = result_df.loc[result_df['collinearity'] >=1]\n",
    "scatter = inliers.plot.scatter(\n",
    "    x='spanned_area', \n",
    "    y='error',\n",
    "    s=10,\n",
    "    c='distance_to_next_ref_pt',\n",
    "    colormap='viridis',\n",
    "    alpha=0.8,\n",
    "    colorbar=False\n",
    "    # figsize=(12, 10)23\n",
    ")\n",
    "cbar = plt.colorbar(scatter.collections[0], ax=scatter)\n",
    "# cbar.ax.set_title('distance to next reference point', ha='center', va='center', rotation=270)\n",
    "cbar.set_label('distance to next reference point [px]')\n",
    "plt.grid(False)\n",
    "plt.ylabel('error [px]')\n",
    "plt.xlabel('spanned area [px]')\n",
    "plt.savefig('output/area_distance_error.png', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
